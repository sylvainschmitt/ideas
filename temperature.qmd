# Temperature {.unnumbered}

```{r setup}
#| include: false
rm(list = ls()) ; invisible(gc()) ; set.seed(42)
library(tidyverse)
library(terra)
library(sf)
library(spatialreg)
library(spdep)
theme_set(bayesplot::theme_default())
knitr::opts_chunk$set(
  echo = F, message = F, warning = F, fig.height = 6, fig.width = 8,
  cache = T, cache.lazy = F)
temp_pal <- c("#053061", "#f7f7f7", "#67001f")
```

```{r data}
#| include: false
tas_ind <- rast("results/data/modis_indices.nc")
tas <- rast("results/data/modis_anomalies.nc")
deforest <- rast("results/data/tmf_deforested_2022_2000.tif") %>% 
  resample(tas)
data <- as.data.frame(deforest, xy = T) %>% 
  left_join(as.data.frame(tas, xy = TRUE)) %>% 
  na.omit() %>% 
  mutate(intact = 1) %>% 
  filter(deforest > 1)
```

## Amazon (NW)

Following @butt2023, we used land surface temperature (LST) data from MOD11A2 version 6 MODIS 8-d LST data up-scaled at 0.05-degree resolution grid. We excluded data where the estimated emissivity error was greater than 0.02 and where the LST error was greater than 1 K. Extensive cloud cover can reduce the spatial and temporal availability of satellite data. For this reason, we focus our analysis on the dry season when there is less cloud cover. We thus worked with the driest month computed independently for each cell and each year based on CHIRPS data (see precipitation section). Dry season surface temperature changes were then calculated by comparing temperature of the driest month for two periods at the end (2020 to 2022) and start (2001 to 2003) of the study period. Using 3-y averages reduces the influences of climate variability. We computed variations in mean temperature. Monthly or seasonal indices could be used at a later stage, but we must also include seasonal variations across space. Daily extrema could also be used.

```{r ca2022}
ggplot() +
  tidyterra::geom_spatraster(data = tas_ind) +
  geom_sf(data = st_read("data/capricho/capricho.shp", quiet = TRUE),
          fill = NA, col = "red", linewidth = 1) +
  theme_bw() +
  scale_fill_gradient2(low = temp_pal[1], mid = temp_pal[2], 
                       high = temp_pal[3], midpoint = 30, "째C", na.value = NA) +
  ggtitle("Mean temperature of dryest month in 2022")
```

```{r caanom}
ggplot() +
  tidyterra::geom_spatraster(data = tas) +
  geom_sf(data = st_read("data/capricho/capricho.shp", quiet = TRUE),
          fill = NA, col = "black", linewidth = 0.8) +
  theme_bw() +
  scale_fill_gradient2(low = temp_pal[1], mid = temp_pal[2], 
                       high = temp_pal[3], midpoint = 0, "째C", na.value = NA) +
  ggtitle("Temperature anomalies of the dryest month", "2001:2003 vs 2000:2022")
```

### Comparisons

Comparing deforestation surfaces to climate anomalies seems to indicate an increase in temperature with increasing deforestation surfaces. But caution should be taken because of possible spatial proximity between deforested pixels that could confound with the spatial structure of climate anomalies.

```{r cacomp}
step <- 0.1
top <- 10
data %>% 
  mutate(deforest = cut(deforest, breaks = seq(0, top, by = step),
                               labels = seq(0, (top-step), by = step)+step/2)) %>% 
  mutate(deforest = as.numeric(as.character(deforest))) %>% 
  na.omit() %>% 
  ggplot(aes(deforest, tas)) +
  geom_boxplot(aes(group = as.character(deforest))) +
  theme_bw() +
  geom_smooth() +
  xlab("Deforestation surface (km2, 2000-2022)") +
  ylab("January anomalies of mean temperature at surface")
```

### Linear regressions

Classic linear regression without accounting for spatial autocorrelation found no general trend in temperature, but a significant increase in mean temperature of the dryest month (+0.23째C) per deforested $km^2$ in cells of ca. $25 km^2$. Inspecting models residuals revealed a significant spatial autocorrelation but below 0.2 up to several hundred of kilometres questioning the robustness of the results.

```{r calm}
reg <- lm(tas ~ deforest, data)
sjPlot::tab_model(reg)
```

```{r calmcor}
data$res <- residuals(reg) 
n <- 10^3
data2 <- sample_n(data, n)
cor <- pgirmess::correlog(data.frame(data2$x, data2$y), data2$deforest,
                   method = "Moran", nbclass = 30) %>% 
  as.data.frame()
cor %>% 
  ggplot(aes(x = dist.class*100, y = coef)) + 
  geom_point(aes(alpha = p.value < 0.01)) + geom_line() +
  geom_hline(yintercept = 0) +
  theme_bw() +
  xlab("Distance (km)") + ylab("Moran\'s I") +
  scale_x_log10() +
  ylim(-1, 1) +
  ggtitle("Residuals spatial auto-correlation")
```

### Spatial regressions

To account for spatial autocorrelation, we took advantage of a method including spatial autocorrelation in model error (CAR, conditional autoregression see note below). We confirmed a significant effect of deforestation on mean temperature increase in the dryest month (-0.023째C/km2).

```{r sr}
#| eval: false
#| include: false
nb <- dnearneigh(data[c("x", "y")], 0, 10, longlat = T)
sr <- spautolm(tas ~ deforest, data, 
               listw = nb2listw(nb, zero.policy = TRUE), family = "CAR")
save(sr, file = "save/tas.Rdata")
```

```{r}
load("save/tas.Rdata")
summary(sr)
```

```{r casrcor}
#| eval: false
#| include: false
data$res <- residuals(sr)
n <- 10^3
data2 <- sample_n(data, n)
cor <- pgirmess::correlog(data.frame(data2$x, data2$y), data2$deforest,
                   method = "Moran", nbclass = 30) %>% 
  as.data.frame()
cor %>% 
  ggplot(aes(x = dist.class*100, y = coef)) + 
  geom_point(aes(alpha = p.value < 0.01)) + geom_line() +
  geom_hline(yintercept = 0) +
  theme_bw() +
  xlab("Distance (km)") + ylab("Moran\'s I") +
  scale_x_log10() +
  ylim(-1, 1) +
  ggtitle("Residuals spatial auto-correlation")
```

### Spatial methods

We explored multiple tool and methods to account for spatial autocorrelation in the regression. Below are listed the different options and the rational of the choice.

-   spautolm from spatialreg based on neighbours of dnearneigh from spdep
    -   this method is based on CAR (could be SAR)
    -   neighbourhood is defined using the regular matrix based on distance: 'dnearneigh(data_test\[c("x", "y")\], 0, 10, longlat = T)'
    -   neighbourhood can be plotted: 'plot(data_adj, data_test\[c("x", "y")\])'
    -   the regression is straightforward: 'spautolm(formula, data, listw = nb2listw(data_adj, zero.policy = TRUE), family = "CAR")'
    -   the tool quickly saturated RAM, depending on both the number of observation (1,000 start to block) and the number of neighbours per observation (10,000 for 10km)
-   icar from brms with manual build of distance matrix
    -   this method is based on CAR (other available)
    -   distance matrix can be computed as follow: 'distances \<- as.matrix(dist(data_test\[c("x", "y")\])\*(1/0.01)); W \<- array(0, c(N, N)); W\[distances \<= 10\] \<- 1'
    -   brms can take advantage of within chain parralelisation, does not overload memory, but might be slow and have convergence issue
    -   the regression is straightforward: 'brm(formula + car(W, type = "icar"), data = data_test, data2 = list(W = W), cores = 20)'
-   spNNGP from spNNGP
    -   Gaussian univariate Bayesian spatial regression models using Nearest Neighbor Gaussian Processes
    -   neighbourhood does not need to be defined
    -   does not overload memory and is very fast (can still take a few minutes for a whole dataset of 15,000 observations)
    -   the regression is less straightforward, see code above
    -   the model only use one chain and post-warmup convergence is questionable despite high acceptance rate
-   CAR can be manually implemented in stan using multi_normal_prec but seems very slow
